{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\Samu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nltk\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from langdetect import detect, LangDetectException\n",
    "import openai\n",
    "nltk.download('vader_lexicon')\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "# openai.api_key = \"sk-8\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../data/original/train.csv'\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=314)\n",
    "\n",
    "final_train_df = df.copy()\n",
    "\n",
    "predictive_path = '../data/original/predictive.csv'\n",
    "predictive_df = pd.read_csv(predictive_path)\n",
    "\n",
    "processed_train_csv_path = '../data/processed/nbhds/train.csv'\n",
    "processed_test_csv_path = '../data/processed/nbhds/test.csv'\n",
    "processed_final_train_csv_path = '../data/processed/nbhds/final_train.csv'\n",
    "processed_predictive_csv_path = '../data/processed/nbhds/predictive.csv'\n",
    "\n",
    "processed_train_df = pd.read_csv(processed_train_csv_path)\n",
    "processed_test_df = pd.read_csv(processed_test_csv_path)\n",
    "processed_final_train_df = pd.read_csv(processed_final_train_csv_path)\n",
    "processed_predictive_df = pd.read_csv(processed_predictive_csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_english(text):\n",
    "    try:\n",
    "        return detect(text) == 'en'\n",
    "    except LangDetectException:\n",
    "        return False\n",
    "\n",
    "# def translate_to_english(text):\n",
    "#     try:\n",
    "#         response = openai.ChatCompletion.create(\n",
    "#             model=\"gpt-4\",\n",
    "#             messages=[\n",
    "#                 {\"role\": \"system\", \"content\": \"You are a helpful assistant that translates text to English.\"},\n",
    "#                 {\"role\": \"user\", \"content\": f\"Translate the following text to English:\\n\\n{text}\"}\n",
    "#             ],\n",
    "#             max_tokens=1000,\n",
    "#             temperature=0\n",
    "#         )\n",
    "#         print('Translated to English:', response['choices'][0]['message']['content'].strip())\n",
    "#         return response['choices'][0]['message']['content'].strip()\n",
    "#     except:\n",
    "#         print('Failed to translate to English:', text)\n",
    "#         return text\n",
    "\n",
    "def get_sentiment_score(text):\n",
    "    return sia.polarity_scores(text)['compound']\n",
    "\n",
    "\n",
    "def process_dataframe(df):\n",
    "\n",
    "    df['combined_text'] = df['name'].astype(str) + ' ' + df['description'].astype(str)\n",
    "    df['description_sentiment'] = df['combined_text'].apply(get_sentiment_score)\n",
    "    df['no_reviews'] = df['reviews'].apply(lambda x: 1 if not isinstance(x, str) else 0)\n",
    "    def process_reviews(reviews_str):\n",
    "        if not isinstance(reviews_str, str):\n",
    "            return 0\n",
    "        reviews = reviews_str.split(\"\\n---------------------------------\\n\")\n",
    "        sentiments = []\n",
    "        for review in reviews:\n",
    "            review = review.strip()\n",
    "            if not review:\n",
    "                continue\n",
    "            # if not is_english(review):\n",
    "            #     review = translate_to_english(review)\n",
    "            sentiments.append(get_sentiment_score(review))\n",
    "        return sum(sentiments) / len(sentiments) if sentiments else 0\n",
    "    df['reviews_sentiment'] = df['reviews'].apply(process_reviews)\n",
    "    print(df[['description_sentiment', 'reviews_sentiment', 'no_reviews']])\n",
    "    return df[['description_sentiment', 'reviews_sentiment', 'no_reviews']]\n",
    "\n",
    "\n",
    "description_reviews_sentiment_train = process_dataframe(train_df)\n",
    "description_reviews_sentiment_test = process_dataframe(test_df)\n",
    "description_reviews_sentiment_final_train = process_dataframe(final_train_df)\n",
    "description_reviews_sentiment_predictive = process_dataframe(predictive_df)\n",
    "\n",
    "processed_train_df = pd.concat([processed_train_df, description_reviews_sentiment_train], axis=1)\n",
    "processed_test_df = pd.concat([processed_test_df, description_reviews_sentiment_test], axis=1)\n",
    "processed_final_train_df = pd.concat([processed_final_train_df, description_reviews_sentiment_final_train], axis=1)\n",
    "processed_predictive_df = pd.concat([processed_predictive_df, description_reviews_sentiment_predictive], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       description_sentiment  reviews_sentiment  no_reviews\n",
      "6548                  0.9260           0.922700           0\n",
      "4483                  0.9260           0.743174           0\n",
      "1838                  0.8481           0.692000           0\n",
      "9746                  0.7184           0.000000           1\n",
      "11853                 0.9819           0.832413           0\n",
      "...                      ...                ...         ...\n",
      "11212                 0.9403           0.000000           1\n",
      "1818                  0.3400           0.785122           0\n",
      "7899                  0.5848           0.754911           0\n",
      "12990                 0.8519           0.771450           0\n",
      "3285                  0.0000           0.730759           0\n",
      "\n",
      "[200 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "sample = train_df.sample(200)\n",
    "original_sample = sample.copy()\n",
    "sentiment_sample = process_dataframe(sample)\n",
    "sample = pd.concat([original_sample, sentiment_sample], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_train_csv_path = '../data/processed/sentiment/train.csv'\n",
    "processed_test_csv_path = '../data/processed/sentiment/test.csv'\n",
    "processed_final_train_csv_path = '../data/processed/sentiment/final_train.csv'\n",
    "processed_predictive_csv_path = '../data/processed/sentiment/predictive.csv'\n",
    "\n",
    "processed_train_df.to_csv(processed_train_csv_path, index=False)\n",
    "processed_test_df.to_csv(processed_test_csv_path, index=False)\n",
    "processed_final_train_df.to_csv(processed_final_train_csv_path, index=False)\n",
    "processed_predictive_df.to_csv(processed_predictive_csv_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
